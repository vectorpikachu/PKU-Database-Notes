
@misc{liApproximateNearestNeighbor2016,
  title = {Approximate Nearest Neighbor Search on High Dimensional Data --- Experiments, Analyses, and Improvement (v1.0)},
  author = {Li, Wen and Zhang, Ying and Sun, Yifang and Wang, Wei and Zhang, Wenjie and Lin, Xuemin},
  year = {2016},
  month = oct,
  number = {arXiv:1610.02455},
  eprint = {1610.02455},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1610.02455},
  urldate = {2025-05-22},
  abstract = {Approximate Nearest neighbor search (ANNS) is fundamental and essential operation in applications from many domains, such as databases, machine learning, multimedia, and computer vision. Although many algorithms have been continuously proposed in the literature in the above domains each year, there is no comprehensive evaluation and analysis of their performances. In this paper, we conduct a comprehensive experimental evaluation of many state-of-the-art methods for approximate nearest neighbor search. Our study (1) is cross-disciplinary (i.e., including 16 algorithms in different domains, and from practitioners) and (2) has evaluated a diverse range of settings, including 20 datasets, several evaluation metrics, and different query workloads. The experimental results are carefully reported and analyzed to understand the performance results. Furthermore, we propose a new method that achieves both high query efficiency and high recall empirically on majority of the datasets under a wide range of settings.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Databases},
}

@misc{malkovEfficientRobustApproximate2018,
  title = {Efficient and Robust Approximate Nearest Neighbor Search Using Hierarchical Navigable Small World Graphs},
  author = {Malkov, Yu A. and Yashunin, D. A.},
  year = {2018},
  month = aug,
  number = {arXiv:1603.09320},
  eprint = {1603.09320},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1603.09320},
  urldate = {2025-05-22},
  abstract = {We present a new approach for the approximate K-nearest neighbor search based on navigable small world graphs with controllable hierarchy (Hierarchical NSW, HNSW). The proposed solution is fully graph-based, without any need for additional search structures, which are typically used at the coarse search stage of the most proximity graph techniques. Hierarchical NSW incrementally builds a multi-layer structure consisting from hierarchical set of proximity graphs (layers) for nested subsets of the stored elements. The maximum layer in which an element is present is selected randomly with an exponentially decaying probability distribution. This allows producing graphs similar to the previously studied Navigable Small World (NSW) structures while additionally having the links separated by their characteristic distance scales. Starting search from the upper layer together with utilizing the scale separation boosts the performance compared to NSW and allows a logarithmic complexity scaling. Additional employment of a heuristic for selecting proximity graph neighbors significantly increases performance at high recall and in case of highly clustered data. Performance evaluation has demonstrated that the proposed general metric space search index is able to strongly outperform previous opensource state-of-the-art vector-only approaches. Similarity of the algorithm to the skip list structure allows straightforward balanced distributed implementation.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Data Structures and Algorithms,Computer Science - Information Retrieval,Computer Science - Social and Information Networks},
}

